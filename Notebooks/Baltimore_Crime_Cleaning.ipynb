{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Baltimore Crime Data with Pandas and Analyzing It with Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook records my progress in cleaning the data of an Excel file and re-uploading it. The data will then go in to Tableau for some interesting visualizations and analysis.\n",
    "### If you would like to download the pre-cleaned and finished spreadsheets, simply navigate to the 'BaltCrime' folder under 'other' in the folder of my github.io page.\n",
    "### You can find the link to my [Tableau visualizations here.](https://public.tableau.com/app/profile/jacob.levy3764/viz/BaltimoreCrimeVisualized/Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Outside' 'Inside' 'I' 'O']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#For the beginning of this notebook we'll focus on the first sheet, titled \"Part1_Crime_data\"\n",
    "first_sheet_df = pd.read_excel(\"Baltimore Crime.xlsx\", sheet_name=0)  \n",
    "inside_outside_df = first_sheet_df['Inside_Outside']\n",
    "print(inside_outside_df.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so it's got 5 values. NaN, Inside, Outside, I, O. I want 3: Inside, Outside, and NA.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NA' 'Outside' 'Inside']\n"
     ]
    }
   ],
   "source": [
    "#Making the O's into Outside, I's into Inside, and fill the null stuff with NA, to better match the rest of the dataset.\n",
    "first_sheet_df['Inside_Outside']= inside_outside_df.replace({'O':'Outside', 'I':'Inside'}).fillna('NA')\n",
    "#Let's see if it's 3 unique entries now.\n",
    "print(first_sheet_df['Inside_Outside'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent. Next up we have to split one row into two. CrimeDateTime has the date and the time of the crime, and I'd like date and time to be their own columns to match up better with the dataset. You'll see when I use the .head() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CrimeDate    CrimeTime\n",
      "0  2022/02/19  07:30:00+00\n",
      "1  2022/02/19  03:22:23+00\n",
      "2  2022/02/19  11:20:00+00\n",
      "3  2022/02/19  01:55:00+00\n",
      "4  2022/02/19  10:00:00+00\n"
     ]
    }
   ],
   "source": [
    "df = first_sheet_df['CrimeDateTime']\n",
    "splitTimeDate = df.str.split(expand=True).rename(columns = {0:'CrimeDate', 1:'CrimeTime'})\n",
    "#Showing the newly split and renamed columns.\n",
    "print(splitTimeDate.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! But CrimeTime is in 24 hour time, when I want it in 12 hour (or AM/PM) time. \n",
    "Thankfully, pandas has a way of doing just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    07:30:00 AM\n",
      "1    03:22:23 AM\n",
      "2    11:20:00 AM\n",
      "3    01:55:00 AM\n",
      "4    10:00:00 AM\n",
      "Name: CrimeTime, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Formatting the time format to 12 hour time.\n",
    "splitTimeDate['CrimeTime'] = pd.to_datetime(splitTimeDate['CrimeTime']).dt.strftime('%I:%M:%S %p')\n",
    "print(splitTimeDate['CrimeTime'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, now we're going to combine the dataframe we've been working on with the original, and in the process drop the CrimeDateTime series from there.\n",
    "While we're at it, we're going to drop a few more columns that aren't relevant to our work, and don't have an equivalent in the other sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CrimeCode' 'Location' 'Description' 'Inside/Outside' 'Weapon' 'Post'\n",
      " 'District' 'Neighborhood' 'Latitude' 'Longitude' 'Premise' 'CrimeTime'\n",
      " 'CrimeDate']\n"
     ]
    }
   ],
   "source": [
    "#Out with the old...\n",
    "first_sheet_df.drop(columns = ['CrimeDateTime', 'X', 'Y', 'RowID', 'VRIName', 'Shape', 'GeoLocation', 'Total_Incidents'], axis = 1, inplace = True)\n",
    "#And in with the new!\n",
    "first_sheet_df['CrimeTime'] = splitTimeDate['CrimeTime']\n",
    "first_sheet_df['CrimeDate'] = splitTimeDate['CrimeDate']\n",
    "#And while we're at it, let's rename Inside_Outside to better match the other sheet's equivalent column.\n",
    "first_sheet_df.rename(columns = {'Inside_Outside':'Inside/Outside'}, inplace = True)\n",
    "print(first_sheet_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so we've got our first sheet cleaned and ready for analysis. However, I want to combine it with the second sheet, which records data from 2015 - 2016. \n",
    "The goal here is to merge the columns seamlessly into one dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_sheet_df = pd.read_excel(\"Baltimore Crime.xlsx\", sheet_name=1) \n",
    "#Well, it has some empty columns and data we're not really interested in, so we're gonna drop it. \n",
    "second_sheet_df.drop(columns = ['Location 1', 'crimeCaseNumber', 'Total Incidents'], axis=1,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       96946\n",
      "unique          3\n",
      "top       Outside\n",
      "freq        48987\n",
      "Name: Inside/Outside, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Casting the CrimeDate column to a more appropriate datatype. This will smooth things over when we merge the sheets.\n",
    "second_sheet_df['CrimeDate'] = second_sheet_df['CrimeDate'].dt.date\n",
    "#And just like earlier, we'll have to fix up the Inside/Outside column to have only three unique values.\n",
    "second_sheet_df['Inside/Outside'] = second_sheet_df['Inside/Outside'].replace({'O':'Outside', 'I':'Inside'}).fillna('NA')\n",
    "print(second_sheet_df['Inside/Outside'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CrimeCode' 'Location' 'Description' 'Inside/Outside' 'Weapon' 'Post'\n",
      " 'District' 'Neighborhood' 'Latitude' 'Longitude' 'Premise' 'CrimeTime'\n",
      " 'CrimeDate' 'Country' 'State' 'City']\n"
     ]
    }
   ],
   "source": [
    "combined_sheet_df = pd.concat([first_sheet_df, second_sheet_df])\n",
    "#Just a few more things...\n",
    "#Tableau is picky with location stuff. We're going to add the Country, State, and City as columns to the dataframe. It'll let Tableau read things better.\n",
    "combined_sheet_df['Country'] = 'United States'\n",
    "combined_sheet_df['State'] = 'Maryland'\n",
    "combined_sheet_df['City'] = 'Baltimore'\n",
    "#Let's see our columns now.\n",
    "print(combined_sheet_df.columns.values)\n",
    "\n",
    "#I'm also going to fix up the area names to be more consistent.\n",
    "columnsNeedingTitle = ['Neighborhood', 'District', 'Location', 'Description', 'Weapon', 'Premise']\n",
    "for column in columnsNeedingTitle:\n",
    "    combined_sheet_df[column] = combined_sheet_df[column].str.title()\n",
    "\n",
    "#And there we have it.\n",
    "#If you're trying this out for yourself, this is going to take a while. It's (tragically) a lot of data.\n",
    "combined_sheet_df.to_excel(\"Updated Baltimore Crime.xlsx\", sheet_name='Crimes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks to pandas, manipulating this data was wonderfully simple. We can now see the fruits of our labor visualized through Tableau. [Click here to see the three visualizations I made!](https://public.tableau.com/app/profile/jacob.levy3764/viz/BaltimoreCrimeVisualized/Map)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e848af873f3e812ec2953747a0a3908e80d669a3bbddda1c790465918855cbf2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
